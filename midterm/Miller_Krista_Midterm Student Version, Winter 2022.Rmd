---
title: "COMP 4442 Midterm, Winter 2022"
author: "Krista Miller"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)

library(leaps)
library(ggplot2)
library(tidyverse)
library(GGally)
library(ggpubr)
library("dplyr") 
library(readxl)
library(nortest)
library(lawstat)

```

There are six questions on this midterm, all of which have multiple parts. Please be sure to provide answers to all parts of each question. Each question has an associated .csv file, which you will load into memory at the beginning of the question. All of the included data sets are simulated, so any results should not be taken as evidence for or against the existence of anything in the real world. The data were simulated to minimize the ambiguity and messiness that typifies real data. If you feel that something is ambiguous in a way that impedes your ability to answer the questions, please let me know. 

I believe in you! 

## Question 1: Basic ANOVA - 10 points total

A tire manufacturing company wants to know if different formulations of tire rubber result in differences in tire durability. They are interested in four different rubber formulations ("form"). To test this, 20 tires of each rubber formulation are selected for testing. Aside from the rubber formulation, all 80 tires in this experiment are otherwise exactly the same. The durability of each tire is tested using a durability machine, which mimics the forces and stress a tire is exposed to when installed in a standard sedan driving down a flat asphalt road at 60 miles per hour. The machines tracks how many miles the tire has "traveled" based on the number of rotations of the tire. The durability test stops when the tire's structure fails, which is when the durability machine records the number of traveled miles ("miles"). The data from this hypothetical experiment is contained in the Q1data.csv file. 

Run the code chunk below to load the data into memory before beginning your work on this question. 
```{r }

tires <- read.csv("Q1data.csv", header=TRUE, sep=",") # Loads the CSV file into memory. You may need to adapt this line to work on your computer

tires$form <- as.factor(tires$form)

str(tires)

```

# Q1, Part 1: Assessing the normality of groups assumption (2 points)

You will assess the assumption of normality in two ways: quantitatively and visually.

In this first code chunk, please conduct an appropriate *quantitative* assessment of the normality assumption and display the results.
  
```{r }
# Code for your quantitative assessment of the normality assumption goes here

tires%>%group_by(form)%>%summarize(pval=shapiro.test(miles)$p)

```

In this second code chunk, please conduct an appropriate *visual* assessment of the normality assumption and display the visualization/s you create. 

```{r }

# Code for your visual assessment of the normality assumption goes here

ggqqplot(tires,x="miles",facet.by = "form")

```

# Q1, Part 2: Assessing the equality of variances of groups assumption (2 points)

You will assess the assumption of equality of variances in two ways: quantitatively and visually.

In this first code chunk, please conduct an appropriate *quantitative* assessment of the equality of variances assumption and display the results.
  
```{r }

# Code for your quantitative assessment of the equality of variances assumption goes here

levene.test(tires$miles,tires$form)

```

In this second code chunk, please conduct an appropriate *visual* assessment of the equality of variances assumption and display the visualization/s you create. 

```{r }

# Code for your visual assessment of the equality of variances assumption goes here

ggplot(tires, aes(x=form, y= miles)) + geom_boxplot()

```

# Q1, Part 3: Fitting the ANOVA model (2 points)

Now, you will conduct an ANOVA on the tires data set that can provide an answer to the research question: do different formulations of tire rubber have different durability? Please be sure to display the results of your analysis. 

```{r }

# Code for your ANOVA goes here

tires.aov <- aov(miles~form, data=tires)

# Don't forget to display the results using the summary() function!

summary(tires.aov)

```

# Q1, Part 4: Interpreting the ANOVA results (4 points)

A) What is the null hypothesis being tested by the ANOVA you conducted? Based on the results of your analysis, do you reject or fail to reject this null hypothesis?

Your answer here: The null hypothesis is that the tire groups (forms) have equal means in terms of tire durability (miles). 

B) What do the results of your ANOVA suggest about the research question? That is, what is your answer to the tire manufacturer's research question about tire durability? 

Your answer here: The high p-value (0.793) gives strong evidence supporting this conclusion:  I fail to reject the null hypothesis and conclude that there is not a statistically significant difference in the mean miles traveled among the tire forms. 


## Question 2: Multifactor ANOVA - 10 points 

A health researcher designed an experiment to test the effects of two medications, Lowesterol and Lipidown, on LDL cholesterol levels of people who had been diagnosed as having high cholesterol but no other health problems. He recruited 160 participants, all of whom took two pills each day for 90 days. For 40 participants, both pills were placebos. For 40 participants, one pill contained Lowesterol and the other pill was a placebo. For 40 participants, one pill contained Lipidown and the other pill was a placebo. For the last 40 participants, one pill contained Lowesterol and the other contained Lipidown. After 90 days, each participant gave a blood sample and the LDL level in their blood was recorded. The data from this hypothetical experiment is contained in the Q2data.csv file. 

Run the code chunk below to load the data into memory before beginning your work on this question.
```{r }

drugs <- read.csv("Q2data.csv", header=TRUE, sep=",") # Loads the CSV file into memory. You may need to adapt this line to work on your computer

drugs$lowesterol <- as.factor(drugs$lowesterol)
drugs$lipidown <- as.factor(drugs$lipidown)

str(drugs)

```

# Q2, Part 1: Fitting the factorial ANOVA model (4 points)

Now, you will conduct a two-way ANOVA with an interaction on the drug data. Use post.ldl as the outcome. Please be sure to display the results of your analysis. 

```{r }

# Code for your ANOVA goes here

drugs.aov <- aov(post.ldl~lowesterol * lipidown, data= drugs)

# Don't forget to display the results using the summary() function!

summary(drugs.aov)  
  
```

# Q2, Part 2: Interpreting the factorial ANOVA model (6 points)

Use the output from the factorial ANOVA to answer the following three questions.

A) Is the main effect of Lowesterol significant?

Your answer here (yes/no): no

B) Is the main effect of Lipidown significant?

Your answer here (yes/no): yes

C) Is the interaction between Lipidown and Lowesterol significant?

Your answer here (yes/no): no


## Question 3: Multiple Regression - 20 points total

A security firm contracted by a shopping center wants to examine the factors that contribute to "loss" (theft of money or goods by customers or employees of a store) in the 200 stores in the shopping center. They have four pieces of information reported by the shopping center about each store: the amount of loss in dollars ("loss", continuous), the area of the store in square feet ("area", continuous), the average number of people who walk into the store on a weekly basis ("traffic", continuous), and whether the store is primarily a retail store (retail=1) or a service-oriented store (retail=0). The data from this hypothetical study is contained in the Q3data.csv file.

Run the code chunk below to load the data into memory before beginning your work on this question.
```{r }

mall <- read.csv("Q3data.csv", header=TRUE, sep=",") # Loads the CSV file into memory. You may need to adapt this line to work on your computer

mall$retail <- as.factor(mall$retail)

str(mall)

```

# Q3, Part 1: Fitting the regression model (2 points)

Now, you will conduct a multiple regression analysis. The outcome for this regression will be loss, and the predictors will be retail, area, and traffic. Be sure to display the results of your analysis. 

```{r }

# Code for your regression goes here

mall.reg <- lm(loss ~ retail+area+traffic, data= mall)

# Don't forget to display the results using the summary() function!

summary(mall.reg)

```


# Q3, Part 2: Checking diagnostic plots (4 points)

Please display the diagnostic plots for the model you fit in the previous part of this question and answer the question below: 

```{r }

# Code for your regression diagnostic plots

par(mfrow = c(2, 2))

plot(mall.reg)

```

A) What is the most obvious problem that all of the diagnostic plots for this model share? 

Your answer here: point 200 is influential in all of the diagnostic plots

B) What would be a good solution to this specific problem?

Your answer here: A good solution is to remove this potentially influential point, and then see how the removal of point #200 changes the model estimates and diagnostic plots. 

# Q3, Part 3: Re-fitting the regression model (4 points)

Now, implement the solution you proposed in the last part and re-fit the regression model. Be sure to display the results of your updated analysis.

```{r }

# Code for any changes you make to implement your solution here
mall.remove <- mall[-c(200),]


# Code for your re-fitted regression goes here

mall.reg.change <- lm(loss ~ retail+area+traffic, data= mall.remove)

# Don't forget to display the results of your analysis using the summary() function!

summary(mall.reg.change)  
  
```

Next, display the updated diagnostic plots and answer the question below

```{r }

# Display your updated diagnostic plots here

par(mfrow = c(2, 2))

plot(mall.reg.change)

```

Did your solution to the problem you identified in Q3, Part 2 noticeably improve the diagnostic plots of the model?

Your answer here: Yes


# Q3, Part 4: Interpreting the re-fitted regression model (10 points)

C) Interpret the estimated intercept in the context of the predicted outcome and the predictors.

Your answer here: Without being a primarily retail store, an increase in store area, or increase in traffic, the loss is predicted to be $3.59. 

D) Interpret the coefficient associated with retail:

Your answer here: For a primarily retail store, (and no increase in store area or increase in traffic), the loss is predicted to be $8.53.  

E) What is the predicted amount of loss for a non-retail store that has an area of 1000 square feet and average weekly traffic of 200?

= 3.59+ 0(4.94) +1000(0.999)+ 200(0.500)

Predicted amount of loss= $1,102.59

## Question 4: Automated model selection - 30 points total

The data set Q4data.csv contains nine variables: y, x1, x2, x3, x4, x5, x6, x7, and x8. All of these variables are continuous. 

Run the code chunk below to load the data into memory before beginning your work on this question.
```{r }

many.var <- read.csv("Q4data.csv", header=TRUE, sep=",") # Loads the CSV file into memory. You may need to adapt this line to work on your computer

str(many.var)

```

# Q4, Part 1: Forward selection - 10 points

First, you will use forward selection to select a model. The outcome will be y and the pool of potential predictors will include x1, x2, x3, x4, x5, x6, x7, and x8. Be sure to include trace=1 as part of your use of the function. After this, display the model selected using forward selection. 

```{r }

# Code for any preliminary steps goes here

lm.null<- lm(y~1, data= many.var)

# Code for your forward selection goes here

forward.model<- step(lm.null, direction='forward', scope= ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8, trace=1)


```

The model selected by forward selection:

```{r }

# Display the model selected using forward selection here!

summary(forward.model)

```


# Q4, Part 2: Backward selection - 10 points

Next, you will use backward selection to select a model. The outcome will be y and the pool of potential predictors will include x1, x2, x3, x4, x5, x6, x7, and x8. Be sure to include trace=1 or trace=TRUE as part of your use of the function. After this, display the model selected using backward selection. 

```{r }

# Code for any preliminary steps goes here

lm.full<- lm(y ~ ., data=many.var)

# Code for your backward selection goes here

backward.model<- step(lm.full, direction ="backward", trace=1)


```

The model selected by backward selection:

```{r }

# Display the model selected using backward selection here!

summary(backward.model)

```

# Q4, Part 3: Best subsets selection - 10 points

Finally, you will use best subsets selection to select a model. The outcome will be y and the pool of potential predictors will include x1, x2, x3, x4, x5, x6, x7, and x8. *Be sure to display a table (filled with either stars or TRUE/FALSE values) that shows which predictors were included in the best models of each size* and *display a plot showing the BIC values of the best models of each size*. After this, display the model selected using best subsets selection. 

```{r }
# Code for any preliminary steps goes here
best<- regsubsets(y~., data=many.var, method= "exhaustive", nvmax=8, nbest=1)
# Code for your best subsets selection goes here, including your table and plot as requested in the question prompt
summary(best) #star table
subsets<- summary(best)$which
subsets #TRUE/FALSE table

qplot(1:length(summary(best)$bic),summary(best)$bic)   # Visualization of BICs
best.subset.bic<-which(summary(best)$bic==min(summary(best)$bic))[1] # Min function searches BICs and shows model number
best.subset.bic  #model of length 5 has minimum BIC- corresponds to x1, x2, x3, x4, x7

varnames<-attr(subsets,"dimnames")[[2]]
varnames.best <- varnames[subsets[best.subset.bic,]] 
varnames.best
```

The model selected by best subsets selection:

```{r }

# Display the model selected using best subsets selection here!
bestsubsets.model = lm(y~x1+x2+x3+x4+x7, data=many.var) 
summary(bestsubsets.model)

```



## Question 5: Nested model selection - 20 points total 

The data set Q5data.csv contains nine variables: y, x1, x2, x3, x4, x5, x6, x7, and x8. All of these variables are continuous. This is the same data set used in Question 4, but please reload the data set under a new name to ensure no "cross-contamination" between questions. 

Run the code chunk below to load the data into memory before beginning your work on this question.
```{r }

Q5.var <- read.csv("Q5data.csv", header=TRUE, sep=",") # Loads the CSV file into memory. You may need to adapt this line to work on your computer

str(Q5.var)

```

# Q5, Part 1: Identifying nested models - 10 points

I fitted five regression models using different sets of predictors. Run the code chunk below to estimate and view the models I fitted. Review the output for these models and answer the questions below.

```{r }

model.1 = lm(y~x1, data=Q5.var)
model.2 = lm(y~x1+x2, data=Q5.var)
model.3 = lm(y~x1+x3, data=Q5.var)
model.4 = lm(y~x1+x2+x3, data=Q5.var)
model.5 = lm(y~x1+x2+x3+x1:x2+x1:x3+x2:x3+x1:x2:x3, data=Q5.var)

summary(model.1)
summary(model.2)
summary(model.3)
summary(model.4)
summary(model.5)


```

A) If Model 5 (model.5) is considered to be the "full model", which of the remaining models - Models 1, 2, 3, and 4 - are nested relative to it? 

Your answer here: model.1, model.2, model.3, and model.4 are all nested relative to model.5

B) If Model 4 (model.4) is considered to be the "full model", which of the remaining models - Models 1, 2, and 3 - are nested relative to it? 

Your answer here: model.1, model.2, model.3 are all nested relative to model.4

C) If Model 3 (model.3) is considered to be the "full model", which of the remaining models - Models 1 and 2 - are nested relative to it? 

Your answer here: model.1 is nested relative to model.3

D) In the code chunk below, specify a new model that is nested relative to Model 5 AND in which Model 2 is nested. That is, specify a model that fits the nested model relationship depicted below:

Model 5 (7 predictor coefficients) <-- (Your model, 3-6 predictor coefficients) <-- Model 2 (2 predictor coefficients)

Please note that you cannot chose any of the models already fitted in this question. You must specify a model that hasn't yet been fitted. 

```{r }

model.new <- lm(y~x1+x2+x1:x2, data=Q5.var)
  
summary(model.new)

```

# Q5, Part 2: Nested model testing - 10 points

For this part, you will conduct two nested model tests. In the first test, you will test Model 2 and the new model you specified. In the second test, you will test the new model you specified and Model 5. After you've done this, answer the two questions below. 

```{r }

# Your code for the nested model test between model.2 and model.new

m2.vs.new <- anova(model.2, model.new, test='F')
  
m2.vs.new # Displays result

```

```{r }

# Your code for the nested model test between model.new and model.5

new.vs.m5 <- anova(model.new, model.5, test='F')
  
new.vs.m5 # Displays result

```

E) Based on the result of the test between Model 2 and your new model, which model would you choose?

Your answer here: I would choose the new model.  Adding the interaction term has a significant result p = 0.02972)

F) Based on the result of the test between your new model and Model 5, which model would you choose? 

Your answer here: I would choose Model 5.  The more complex model leads to a significantly improved fit over the new model (p= 0.03278).


## Question 6: Basic logistic regression - 10 points total

A state public health agency wants to investigate the presence of dangerous amounts of lead in drinking water across households within the state. Investigators collected tap water samples from 150 single-family homes and obtained information about each house. Based on advice from an environmental agency, the investigators classified a tap water sample as being safe if it had levels below 15 parts per billion (0) or potentially dangerous if it had levels equal to or greater than 15 parts per billion (1). In addition, they tested the "hardness" (i.e, presence of dissolved calcium, magnesium, and other minerals) of the water sample, which they categorized as being low (0) or high (1). They also noted the age of the house in years and the location type of the house (urban, suburban, or rural). The data from this hypothetical study is contained in the Q6data.csv file. 

Run the code chunk below to load the data into memory before beginning your work on this question
```{r }

lead <- read.csv("Q6data.csv", header=TRUE, sep=",") # Loads the CSV file into memory. You may need to adapt this line to work on your computer

str(lead)

```

# Q6, Part 1: Fitting a logistic model - 5 points

Fit a logistic regression model using "danger" (categorical) as the outcome and "age" (continuous), "loc" (categorical), and "hard" (categorical) as predictors. Be sure to display the results of the analysis.

```{r }

danger.model <- glm(formula= danger~ age + loc + hard, data= lead, family= binomial)

# Don't forget to use the summary() function to display your results!

summary(danger.model)

```

# Q6, Part 2: Interpreting a logistic model - 5 points

A) Based on the results of your analyses, which predictor coefficients (i.e, not including the intercept) were significantly different from zero? There is at least one. 

Your answer here: age

B) Of the statistically significant predictor/s you identified in the previous sub-question, which predictor/s (if any) indicate that the presence of a dangerous level of lead is *more likely* as the value of the predictor increases? Which predictors (if any) indicate that that the presence of a dangerous level of lead is *less likely* as the value of the predictor increases? 

Dangerous level of lead more likely as values of predictor/s increase/s (your answer here): age

Dangerous level of lead Less likely as values of predictor/s increase/s (your answer here): none


